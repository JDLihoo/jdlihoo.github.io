---
title: Flower（联邦学习训练框架）
author: JDLihoo
date: 2025-04-08
category: Jekyll
layout: post
---

## 安装依赖
```
pip install flwr
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install tensorflow_cpu -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install flwr_datasets
pip install pytorch-lightning
```

## 代码解释
### Server
```
# .conda/envs/flower/lib/python3.8/site-packages/flwr/server/server.py
# 一共训练多少轮，进行训练
for current_round in range(1, num_rounds + 1):
    # Train model and replace previous global model
    '''
    fit_round函数执行: configure_fit、fit_clients、aggregate_fit
    其中，configure_fit：Get clients and their respective instructions from strategy
    日志为：configure_fit: strategy sampled 2 clients (out of 2)
    其中，fit_clients：Collect `fit` results from all clients participating in this round
    日志为：aggregate_fit: received 2 results and 0 failures
    其中，aggregate_fit：Aggregate training results
    日志为：No fit_metrics_aggregation_fn provided
    '''
    res_fit = self.fit_round(
        server_round=current_round,
        timeout=timeout,
    )

    # Evaluate model using strategy implementation
    res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)

    '''
    Validate current global model on a number of clients.
    evaluate_round函数执行：configure_evaluate
    configure_evaluate：Get clients and their respective instructions from strategy
    日志为：configure_evaluate: strategy sampled 2 clients (out of 2)
    evaluate_clients：Collect `evaluate` results from all clients participating in this round
    日志为：aggregate_evaluate: received 2 results and 0 failures
    aggregate_evaluate：Aggregate the evaluation results
    '''
    # Evaluate model on a sample of available clients
    res_fed = self.evaluate_round(server_round=current_round, timeout=timeout)
```

```
@abstractmethod
    def configure_fit(
        self, server_round: int, parameters: Parameters, client_manager: ClientManager
    ) -> List[Tuple[ClientProxy, FitIns]]:
        """Configure the next round of training.

        Parameters
        ----------
        server_round : int
            The current round of federated learning.
        parameters : Parameters
            The current (global) model parameters.
        client_manager : ClientManager
            The client manager which holds all currently connected clients.

        Returns
        -------
        fit_configuration : List[Tuple[ClientProxy, FitIns]]
            A list of tuples. Each tuple in the list identifies a `ClientProxy` and the
            `FitIns` for this particular `ClientProxy`. If a particular `ClientProxy`
            is not included in this list, it means that this `ClientProxy`
            will not participate in the next round of federated learning.
        """

    def configure_fit(
        self, server_round: int, parameters: Parameters, client_manager: ClientManager
    ) -> List[Tuple[ClientProxy, FitIns]]:
        """Configure the next round of training."""
        config = {}
        if self.on_fit_config_fn is not None:
            # Custom fit config function provided
            config = self.on_fit_config_fn(server_round)
        fit_ins = FitIns(parameters, config)

        # Sample clients
        sample_size, min_num_clients = self.num_fit_clients(
            client_manager.num_available()
        )
        clients = client_manager.sample(
            num_clients=sample_size, min_num_clients=min_num_clients
        )

        # Return client/config pairs
        return [(client, fit_ins) for client in clients]
```
### Client
```

```

[1]: https://pages.github.com